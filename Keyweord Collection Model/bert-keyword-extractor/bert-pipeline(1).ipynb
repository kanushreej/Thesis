{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92166e09-a59c-42c6-ab33-e3bbf5f21369",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "866b27fa-8f23-42dc-ab46-defefde627f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = pipeline(model = \"yanekyuk/bert-keyword-extractor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e43b0147-21c8-4902-aa99-34d3d2aefdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv file\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"ClimateChange_UK.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb7a8956-3e57-4118-b3db-82177e92eb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the data\n",
    "df['body'] = df['body'].fillna('0').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0048320f-d861-44fa-a03e-9cb09774a46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a keyword extraction function\n",
    "def extract_keywords(text):\n",
    "    try:\n",
    "        return extractor(text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting keywords for text: {text} with error {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc2bca6d-896c-47f1-9771-f504fc5990d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function to extract keyword\n",
    "df['keywords'] = df['body'].apply(extract_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a9e7fc-dd16-4cf4-9af0-fa5f51aafd89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62ef5ac9-0655-4e81-ae0e-91decbd2a108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a formatting function\n",
    "def format_keywords(hf_output):\n",
    "    return [(entry['word'], entry['score']) for entry in hf_output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b517562-4a41-4091-94d5-abe10dc91cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['formatted_keywords'] = df['keywords'].apply(format_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45d86ebf-f9ea-4c2a-af5c-0e9316d0056a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To solve the prblem brought by subword tokenization\n",
    "def merge_subwords(keywords):\n",
    "    merged_keywords = []\n",
    "    previous_keyword = None\n",
    "    \n",
    "    for word, score in keywords:\n",
    "        if word.startswith('##'):\n",
    "            if previous_keyword:\n",
    "                # Remove the \"##\" and combine with previous word\n",
    "                previous_keyword = (previous_keyword[0] + word.replace('##', ''), max(previous_keyword[1], score))\n",
    "        else:\n",
    "            if previous_keyword:\n",
    "                # Add the keyword we combined to the list\n",
    "                merged_keywords.append(previous_keyword)\n",
    "            # Update the previous_keyword with current word\n",
    "            previous_keyword = (word, score)\n",
    "    \n",
    "    # Make sure the last word will be added\n",
    "    if previous_keyword:\n",
    "        merged_keywords.append(previous_keyword)\n",
    "        \n",
    "    return merged_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3d1e3a9-af73-41d5-9855-37a52ca98bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['merged_keywords'] = df['formatted_keywords'].apply(merge_subwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "891a95ee-33e8-4452-bd30-ed0748534dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_keywords = df['merged_keywords'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad7c24f2-50e0-4f92-9672-cc83394c72d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "flat_list = list(chain(*all_keywords)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37bf94e7-3501-4fca-8412-40fda678ab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def remove_duplicates(keywords):\n",
    "    keyword_dict = {}\n",
    "    for word, score in keywords:\n",
    "        if word not in keyword_dict or keyword_dict[word] < score:\n",
    "            keyword_dict[word] = score\n",
    "    # Sort keywords based on score\n",
    "    return sorted(keyword_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "unique_keywords = remove_duplicates(flat_list)\n",
    "top_50_keywords = unique_keywords[:50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3352b1d-3efa-4c8b-92b6-bb831df838e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# 定义停用词列表，可以根据需要添加更多停用词\n",
    "stop_words = set([\n",
    "    'a', 'an', 'and', 'the', 'of', 'in', 'to', 'is', 'it', 'that', 'on', 'for', \n",
    "    'with', 'as', 'by', 'at', 'from', 'this', 'be', 'or', 'which', 'but', 'are', \n",
    "    'was', 'were', 'not', 'have', 'has', 'had', 'will', 'would', 'can', 'could', \n",
    "    'should', 'shall', 'may', 'might', 'must', 'do', 'does', 'did','w','T'\n",
    "])\n",
    "\n",
    "def is_valid_word(word):\n",
    "    # 只保留包含字母和数字的单词且不在停用词列表中的单词\n",
    "    return re.match(r'^[A-Za-z0-9]+$', word) is not None and word.lower() not in stop_words\n",
    "\n",
    "def count_frequency(keywords):\n",
    "    keyword_counter = Counter(word for word, _ in keywords if is_valid_word(word))\n",
    "    return sorted(keyword_counter.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "unique_keywords = count_frequency(flat_list)\n",
    "top_50_keywords = unique_keywords[:50]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01963544-804e-4e60-9ef0-eb1d2f8ea6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Anonymous', 0.9999844),\n",
       " ('Judas', 0.99998367),\n",
       " ('Brexit', 0.9999825),\n",
       " ('Axel', 0.9999821),\n",
       " ('Cambridge', 0.9999819),\n",
       " ('EastEnders', 0.99998164),\n",
       " ('brexshit', 0.9999815),\n",
       " ('Iron', 0.9999815),\n",
       " ('granny', 0.9999814),\n",
       " ('Private', 0.99998116),\n",
       " ('Evil', 0.99998),\n",
       " ('Vodafone', 0.9999796),\n",
       " ('Euronews', 0.99997926),\n",
       " ('permission', 0.99997914),\n",
       " ('Butthole', 0.99997914),\n",
       " ('Shrek', 0.999979),\n",
       " ('Hydrogen', 0.9999784),\n",
       " ('breshit', 0.9999783),\n",
       " ('Reddit', 0.99997747),\n",
       " ('Vote', 0.99997735),\n",
       " ('Nigel', 0.9999769),\n",
       " ('Hide', 0.99997675),\n",
       " ('Firefox', 0.9999765),\n",
       " ('Eurotunnel', 0.99997616),\n",
       " ('Empire', 0.9999759),\n",
       " ('Glorious', 0.9999759),\n",
       " ('Brexitspeak', 0.9999759),\n",
       " ('Brawndo', 0.9999758),\n",
       " ('Politico', 0.9999757),\n",
       " ('McVey', 0.9999757),\n",
       " ('Fast', 0.99997556),\n",
       " ('Stockholm', 0.99997556),\n",
       " ('Next', 0.99997556),\n",
       " ('Sinn', 0.9999753),\n",
       " ('Verhofstadt', 0.9999753),\n",
       " ('Unilever', 0.9999753),\n",
       " ('fifth', 0.9999753),\n",
       " ('Crocodile', 0.9999751),\n",
       " ('Rafael', 0.9999751),\n",
       " ('Brexir', 0.99997497),\n",
       " ('NordStream', 0.99997497),\n",
       " ('schengan', 0.9999747),\n",
       " ('Friede', 0.9999746),\n",
       " ('paywall', 0.9999745),\n",
       " ('T', 0.99997437),\n",
       " ('WhatsApp', 0.999974),\n",
       " ('Greenpeace', 0.999974),\n",
       " ('Raspberry', 0.999974),\n",
       " ('Undercover', 0.9999739),\n",
       " ('Julian', 0.9999738)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_50_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a94a58be-48c4-4b71-b65c-d6f12368f4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_path = 'Keywords_Brexit[Score].csv'\n",
    "if not os.path.exists(output_path):\n",
    "    df_keywords = pd.DataFrame(top_50_keywords, columns=['Keyword', 'Score'])\n",
    "    df_keywords.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da91e92c-ee0a-4bc6-a9fb-0bd0e58cd201",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
